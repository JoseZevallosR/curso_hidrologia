{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9212b524-d2d1-4d94-9889-0fdc2b14c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def identify_best_column_with_data(df, target_station):\n",
    "    \"\"\"\n",
    "    Identifica la mejor columna que tiene la menor cantidad de valores nulos\n",
    "    en las filas donde la estación objetivo tiene valores faltantes.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame que contiene las estaciones y los datos de las mismas.\n",
    "    - target_station: La estación que tiene valores faltantes y que se quiere completar.\n",
    "\n",
    "    Returns:\n",
    "    - best_column: Nombre de la columna con la menor cantidad de valores nulos en las filas donde la estación objetivo tiene valores faltantes.\n",
    "    \"\"\"\n",
    "    # Filtrar las filas donde la estación objetivo tiene valores NaN\n",
    "    target_nan_df = df[df[target_station].isna()]\n",
    "\n",
    "    # Verificar las columnas que tienen la menor cantidad de NaN en esas mismas filas\n",
    "    missing_counts = target_nan_df.drop(columns=[target_station]).isna().sum()\n",
    "\n",
    "    # Seleccionar la columna con la menor cantidad de NaN\n",
    "    best_column = missing_counts.idxmin()\n",
    "\n",
    "    return best_column\n",
    "\n",
    "\n",
    "# Function to perform train-test split and complete missing data using regression\n",
    "def complete_missing_data(df, target_station):\n",
    "    # Drop rows with NaN values in the target station\n",
    "    # Create a copy of the dropped rows\n",
    "    dropped_df = df[df.isna().any(axis=1)]\n",
    "\n",
    "    # Filtrar las filas donde target_station es NaN\n",
    "    target_nan_df = df[df[target_station].isna()]\n",
    "\n",
    "    # Filtrar las filas donde el resto de las columnas no son NaN\n",
    "    target_nan_df_non_nan_other_columns_df = target_nan_df[target_nan_df.drop(columns=[target_station]).notna().all(axis=1)]\n",
    "\n",
    "    # Obtener las filas que están en dropped_df pero no en target_nan_df_non_nan_other_columns_df\n",
    "    rows_to_keep = dropped_df.index.difference(target_nan_df_non_nan_other_columns_df.index)\n",
    "    dropped_df_not_in_target_nan = dropped_df.loc[rows_to_keep]\n",
    "\n",
    "    # Drop the rows with NaN values in 'target_station' from the original DataFrame\n",
    "    remaining_df = df.dropna()\n",
    "    \n",
    "    # Train-test split (70% train, 30% test)\n",
    "    train_df, test_df = train_test_split(remaining_df, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize regression models\n",
    "    linear_reg = LinearRegression()\n",
    "    random_forest_reg = RandomForestRegressor()\n",
    "\n",
    "    # Define performance metric (RMSE in this example)\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    # Train models on the training set\n",
    "    X_train = train_df.drop([target_station, 'Fecha'], axis=1)\n",
    "    y_train = train_df[target_station]\n",
    "    linear_reg.fit(X_train, y_train)\n",
    "    random_forest_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate models on the test set\n",
    "    X_test = test_df.drop([target_station, 'Fecha'], axis=1)\n",
    "    y_test = test_df[target_station]\n",
    "    linear_reg_rmse = root_mean_squared_error(y_test, linear_reg.predict(X_test))\n",
    "    random_forest_rmse = root_mean_squared_error(y_test, random_forest_reg.predict(X_test))\n",
    "\n",
    "    # Choose the best model based on performance (lower RMSE in this case)\n",
    "    if linear_reg_rmse < random_forest_rmse:\n",
    "        selected_model = linear_reg\n",
    "        selected_model_name = 'Linear Regression'\n",
    "        selected_model_rmse = linear_reg_rmse\n",
    "    else:\n",
    "        selected_model = random_forest_reg\n",
    "        selected_model_name = 'Random Forest'\n",
    "        selected_model_rmse = random_forest_rmse\n",
    "\n",
    "    # Use the selected model to complete missing values in the target station\n",
    "    feature_names = X_train.columns\n",
    "    for index, row in target_nan_df_non_nan_other_columns_df.iterrows():\n",
    "        if pd.isnull(row[target_station]):\n",
    "            X_pred = row.drop([target_station, 'Fecha']).values.reshape(1, -1)\n",
    "            X_pred_df = pd.DataFrame(X_pred, columns=feature_names)\n",
    "            predicted_value = selected_model.predict(X_pred_df)[0]\n",
    "\n",
    "            # Check if the predicted value is negative or close to 0\n",
    "            if predicted_value < 0 or np.isclose(predicted_value, 0):\n",
    "                predicted_value = 0\n",
    "                \n",
    "            target_nan_df_non_nan_other_columns_df.loc[index, target_station] = np.round(predicted_value,2)\n",
    "\n",
    "    # Merge them back together\n",
    "    merged_df = pd.concat([target_nan_df_non_nan_other_columns_df, remaining_df,dropped_df_not_in_target_nan], ignore_index=True)\n",
    "    merged_df.sort_values(by='Fecha', inplace=True)\n",
    "    return merged_df, selected_model_name, linear_reg_rmse,random_forest_rmse\n",
    "\n",
    "# Cálculo de NaN y completar hasta que no haya valores faltantes\n",
    "def complete_until_no_nan(df):\n",
    "    nan_percentages = df.isna().mean() * 100  # Porcentaje de valores NaN\n",
    "    ordered_columns = nan_percentages.sort_values().index.tolist()\n",
    "    ordered_columns.pop(0)  # Eliminar la columna de 'Fecha'\n",
    "    print(ordered_columns)\n",
    "\n",
    "    resultados = {\n",
    "        'Gauge': [],\n",
    "        'Selected Model': []\n",
    "    }\n",
    "\n",
    "    previous_nan_sum = nan_percentages.sum()  # Sumar NaN antes de empezar\n",
    "\n",
    "    # Iterar hasta que no queden valores faltantes\n",
    "    while nan_percentages.sum() > 0:\n",
    "        print(f\"Porcentajes de NaN: \\n{nan_percentages}\")\n",
    "        \n",
    "        for gauge in ordered_columns:\n",
    "            if df[gauge].isna().sum() > 0:  # Solo completar si la estación tiene valores faltantes\n",
    "                # Completación inicial usando el mejor método\n",
    "                df, model_name, linear_reg_rmse, random_forest_rmse = complete_missing_data(df, gauge)\n",
    "                resultados['Gauge'].append(gauge)\n",
    "                resultados['Selected Model'].append(model_name)\n",
    "                print(f\"Selected Model for {gauge}: {model_name}\")\n",
    "\n",
    "        # Recalcular los porcentajes de NaN después de completar los datos\n",
    "        nan_percentages = df.isna().mean() * 100\n",
    "        current_nan_sum = nan_percentages.sum()\n",
    "\n",
    "        # Si no mejora el porcentaje de NaN, hacer regresión simple\n",
    "        if current_nan_sum >= previous_nan_sum:\n",
    "            print(\"No hubo mejora en los valores faltantes, buscando la mejor columna para completar...\")\n",
    "            for gauge in ordered_columns:\n",
    "                if df[gauge].isna().sum() > 0:\n",
    "                    # Identificar la mejor columna con menos NaN para hacer la regresión\n",
    "                    best_column = identify_best_column_with_data(df.iloc[:, 1:], gauge)\n",
    "                    print(f\"Usando la columna {best_column} para completar {gauge}\")\n",
    "                    \n",
    "                    # Hacer regresión simple usando la mejor columna\n",
    "                    df = simple_regression(df, best_column, gauge)\n",
    "                    print(f\"Regresión simple completada para {gauge}\")\n",
    "\n",
    "        # Actualizamos el porcentaje de NaN para la siguiente iteración\n",
    "        previous_nan_sum = current_nan_sum\n",
    "\n",
    "    return df, pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "767c2688-6727-4cf4-b1eb-c7546fdcfe3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>chusis</th>\n",
       "      <th>chalaco</th>\n",
       "      <th>huamarca</th>\n",
       "      <th>huancabamba</th>\n",
       "      <th>miraflores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Fecha  chusis  chalaco  huamarca  huancabamba  miraflores\n",
       "0  1980-01-01     0.0      0.0       0.4          2.1         0.0\n",
       "1  1980-01-02     0.0      0.0       0.0          0.0         0.0\n",
       "2  1980-01-03     0.0      0.0       0.0          1.5         0.0\n",
       "3  1980-01-04     0.0      0.0       0.0          0.0         0.0\n",
       "4  1980-01-05     0.0      0.0       0.0          0.0         0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs=pd.read_csv('../data/Estaciones/gauge.csv',sep=',')\n",
    "#obs['Fecha'] = pd.to_datetime(obs['Fecha'], dayfirst=True)\n",
    "#obs['Fecha'] = pd.to_datetime(obs['Fecha'])\n",
    "#obs.set_index('Fecha',inplace=True)\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3153972b-27a6-4a3d-a795-f230f45093fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huancabamba', 'huamarca', 'chalaco', 'miraflores', 'chusis']\n",
      "Porcentajes de NaN: \n",
      "Fecha           0.000000\n",
      "chusis         17.406340\n",
      "chalaco         4.178674\n",
      "huamarca        3.940922\n",
      "huancabamba     3.350144\n",
      "miraflores      7.536023\n",
      "dtype: float64\n",
      "Selected Model for huancabamba: Linear Regression\n",
      "Selected Model for huamarca: Linear Regression\n",
      "Selected Model for chalaco: Linear Regression\n",
      "Selected Model for miraflores: Linear Regression\n",
      "Selected Model for chusis: Linear Regression\n",
      "Porcentajes de NaN: \n",
      "Fecha          0.000000\n",
      "chusis         6.563401\n",
      "chalaco        1.988473\n",
      "huamarca       2.672911\n",
      "huancabamba    2.759366\n",
      "miraflores     5.036023\n",
      "dtype: float64\n",
      "Selected Model for huancabamba: Linear Regression\n",
      "Selected Model for huamarca: Linear Regression\n",
      "Selected Model for chalaco: Linear Regression\n",
      "Selected Model for miraflores: Random Forest\n",
      "Selected Model for chusis: Linear Regression\n",
      "No hubo mejora en los valores faltantes, buscando la mejor columna para completar...\n",
      "Usando la columna huamarca para completar huancabamba\n",
      "Regresión simple completada para huancabamba\n",
      "Usando la columna huamarca para completar chalaco\n",
      "Regresión simple completada para chalaco\n",
      "Usando la columna chalaco para completar miraflores\n",
      "Regresión simple completada para miraflores\n",
      "Usando la columna chalaco para completar chusis\n",
      "Regresión simple completada para chusis\n",
      "Porcentajes de NaN: \n",
      "Fecha          0.000000\n",
      "chusis         6.563401\n",
      "chalaco        1.988473\n",
      "huamarca       2.672911\n",
      "huancabamba    2.759366\n",
      "miraflores     5.036023\n",
      "dtype: float64\n",
      "Selected Model for huancabamba: Linear Regression\n",
      "Selected Model for huamarca: Linear Regression\n",
      "Selected Model for miraflores: Random Forest\n",
      "Porcentajes de NaN: \n",
      "Fecha          0.000000\n",
      "chusis         0.000000\n",
      "chalaco        0.000000\n",
      "huamarca       1.635946\n",
      "huancabamba    1.635946\n",
      "miraflores     0.229477\n",
      "dtype: float64\n",
      "Selected Model for huancabamba: Random Forest\n",
      "Selected Model for huamarca: Linear Regression\n",
      "Selected Model for miraflores: Random Forest\n",
      "No hubo mejora en los valores faltantes, buscando la mejor columna para completar...\n",
      "Usando la columna chusis para completar huancabamba\n",
      "Regresión simple completada para huancabamba\n",
      "Usando la columna chusis para completar huamarca\n",
      "No hay suficientes datos para realizar regresión en la estación: huamarca\n",
      "Regresión simple completada para huamarca\n",
      "Usando la columna chusis para completar chalaco\n",
      "Regresión simple completada para chalaco\n",
      "Usando la columna chusis para completar miraflores\n",
      "No hay suficientes datos para realizar regresión en la estación: miraflores\n",
      "Regresión simple completada para miraflores\n",
      "Porcentajes de NaN: \n",
      "Fecha          0.000000\n",
      "chusis         0.000000\n",
      "chalaco        0.000000\n",
      "huamarca       1.635946\n",
      "huancabamba    1.635946\n",
      "miraflores     0.229477\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_completado, resultados_df \u001b[38;5;241m=\u001b[39m complete_until_no_nan(obs)\n",
      "Cell \u001b[1;32mIn[83], line 128\u001b[0m, in \u001b[0;36mcomplete_until_no_nan\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gauge \u001b[38;5;129;01min\u001b[39;00m ordered_columns:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df[gauge]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Solo completar si la estación tiene valores faltantes\u001b[39;00m\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;66;03m# Completación inicial usando el mejor método\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m         df, model_name, linear_reg_rmse, random_forest_rmse \u001b[38;5;241m=\u001b[39m complete_missing_data(df, gauge)\n\u001b[0;32m    129\u001b[0m         resultados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGauge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(gauge)\n\u001b[0;32m    130\u001b[0m         resultados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelected Model\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_name)\n",
      "Cell \u001b[1;32mIn[83], line 56\u001b[0m, in \u001b[0;36mcomplete_missing_data\u001b[1;34m(df, target_station)\u001b[0m\n\u001b[0;32m     53\u001b[0m remaining_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Train-test split (70% train, 30% test)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m train_test_split(remaining_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Initialize regression models\u001b[39;00m\n\u001b[0;32m     59\u001b[0m linear_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\telemac\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\telemac\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2778\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2775\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2777\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2778\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2779\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2780\u001b[0m )\n\u001b[0;32m   2782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\telemac\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2408\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2405\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2412\u001b[0m     )\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "df_completado, resultados_df = complete_until_no_nan(obs)\n",
    "# print(resultados_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4827cfe3-5f6f-43e3-ab3b-6bfe8ae03db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gauge</th>\n",
       "      <th>Selected Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huancabamba</td>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gauge     Selected Model\n",
       "0  huancabamba  Linear Regression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50212e1b-fae8-4116-b35f-95af7111178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs['Fecha'] = pd.to_datetime(obs['Fecha'])\n",
    "#obs.set_index('Fecha',inplace=True)\n",
    "#plt.figure(figsize=(15,10))\n",
    "#sns.heatmap(obs.isnull(), cbar=False)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d502b8a7-3016-4552-95ea-0312c5d3e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_completado['Fecha'] = pd.to_datetime(df_completado['Fecha'])\n",
    "#df_completado.set_index('Fecha',inplace=True)\n",
    "#plt.figure(figsize=(15,10))\n",
    "#sns.heatmap(df_completado.isnull(), cbar=False)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbaa49-f723-46ec-a761-616a11318914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
